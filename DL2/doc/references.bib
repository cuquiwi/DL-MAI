@article{Chung,
abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
archivePrefix = {arXiv},
arxivId = {1412.3555},
author = {Chung, Junyoung and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
eprint = {1412.3555},
file = {:home/senne/Documents/Mendeley Desktop/Chung, Gulcehre, Cho/Unknown/Chung, Gulcehre, Cho - Unknown - Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.pdf:pdf},
mendeley-groups = {VAKKEN/DL/LAB 2},
title = {{Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}},
url = {http://arxiv.org/abs/1412.3555},
year = {2014}
}
@inproceedings{Cho,
abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
archivePrefix = {arXiv},
arxivId = {1409.1259},
author = {Cho, Kyunghyun and van Merrienboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
booktitle = {Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation},
doi = {10.3115/v1/w14-4012},
eprint = {1409.1259},
file = {:home/senne/Documents/Mendeley Desktop/Cho et al/Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation/Cho et al. - 2015 - On the Properties of Neural Machine Translation Encoder–Decoder Approaches.pdf:pdf},
mendeley-groups = {VAKKEN/DL/LAB 2},
pages = {103--111},
title = {{On the Properties of Neural Machine Translation: Encoder–Decoder Approaches}},
year = {2015}
}
@techreport{Goel2014,
abstract = {In this paper, we propose a generic technique to model temporal dependencies and sequences using a combination of a recurrent neu-ral network and a Deep Belief Network. Our technique, RNN-DBN, is an amalgamation of the memory state of the RNN that allows it to provide temporal information and a multi-layer DBN that helps in high level representation of the data. This makes RNN-DBNs ideal for sequence generation. Further, the use of a DBN in conjunction with the RNN makes this model capable of significantly more complex data representation than an RBM. We apply this technique to the task of polyphonic music generation.},
archivePrefix = {arXiv},
arxivId = {1412.7927v1},
author = {Goel, Kratarth and Vohra, Raunaq and Sahoo, J K},
eprint = {1412.7927v1},
file = {:home/senne/Documents/Mendeley Desktop/Goel, Vohra, Sahoo/Unknown/Goel, Vohra, Sahoo - 2014 - Polyphonic Music Generation by Modeling Temporal Dependencies Using a RNN-DBN.pdf:pdf},
keywords = {()},
mendeley-groups = {VAKKEN/DL/LAB 2},
title = {{Polyphonic Music Generation by Modeling Temporal Dependencies Using a RNN-DBN}},
year = {2014}
}
@techreport{Mangal,
abstract = {Traditionally, music was treated as an analogue signal and was generated manually. In recent years, music is conspicuous to technology which can generate a suite of music automatically without any human intervention. To accomplish this task, we need to overcome some technical challenges which are discussed descriptively in this paper. A brief introduction about music and its components is provided in the paper along with the citation and analysis of related work accomplished by different authors in this domain. Main objective of this paper is to propose an algorithm which can be used to generate musical notes using Recurrent Neural Networks (RNN), principally Long Short-Term Memory (LSTM) networks. A model is designed to execute this algorithm where data is represented with the help of musical instrument digital interface (MIDI) file format for easier access and better understanding. Preprocessing of data before feeding it into the model, revealing methods to read, process and prepare MIDI files for input are also discussed. The model used in this paper is used to learn the sequences of polyphonic musical notes over a single-layered LSTM network. The model must have the potential to recall past details of a musical sequence and its structure for better learning. Description of layered architecture used in LSTM model and its intertwining connections to develop a neural network is presented in this work. This paper imparts a peek view of distributions of weights and biases in every layer of the model along with a precise representation of losses and accuracy at each step and batches. When the model was thoroughly analyzed, it produced stellar results in composing new melodies.},
author = {Mangal, Sanidhya and Modak, Rahul and Joshi, Poorva},
file = {:home/senne/Documents/Mendeley Desktop/Mangal, Modak, Joshi/Unknown/Mangal, Modak, Joshi - Unknown - LSTM Based Music Generation System.pdf:pdf},
keywords = {LSTM,MIDI,Melodies,Music,Neural Network,RNN},
mendeley-groups = {VAKKEN/DL/LAB 2},
title = {{LSTM Based Music Generation System}}
}
@techreport{Oord2016,
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
archivePrefix = {arXiv},
arxivId = {1609.03499},
author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
eprint = {1609.03499},
file = {:home/senne/Documents/Mendeley Desktop/Oord et al/Unknown/Oord et al. - 2016 - WaveNet A Generative Model for Raw Audio.pdf:pdf},
mendeley-groups = {VAKKEN/DL/LAB 2},
title = {{WaveNet: A Generative Model for Raw Audio}},
url = {http://arxiv.org/abs/1609.03499},
year = {2016}
}
@inproceedings{VanDenOord2016,
abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two- dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNel dataset. Samples generated from the model appear crisp, varied and globally coherent.},
archivePrefix = {arXiv},
arxivId = {1601.06759},
author = {{Van Den Oord}, A{\"{a}}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
booktitle = {33rd International Conference on Machine Learning, ICML 2016},
eprint = {1601.06759},
file = {:home/senne/Documents/Mendeley Desktop/Van Den Oord, Kalchbrenner, Kavukcuoglu/33rd International Conference on Machine Learning, ICML 2016/Van Den Oord, Kalchbrenner, Kavukcuoglu - 2016 - Pixel recurrent neural networks.pdf:pdf},
isbn = {9781510829008},
mendeley-groups = {VAKKEN/DL/LAB 2},
pages = {2611--2620},
title = {{Pixel recurrent neural networks}},
volume = {4},
year = {2016}
}
@article{Radford,
abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension , and summarization, are typically approached with supervised learning on task-specific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset-matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
file = {:home/senne/Documents/Mendeley Desktop/Radford et al/Unknown/Radford et al. - 2018 - Language Models are Unsupervised Multitask Learners.pdf:pdf},
mendeley-groups = {VAKKEN/DL/LAB 2},
title = {{Language Models are Unsupervised Multitask Learners}},
year = {2018}
}
@incollection{Goodfellow2014,
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Ghahramani, Z and Welling, M and Cortes, C and Lawrence, N D and Weinberger, K Q},
file = {:home/senne/Documents/Mendeley Desktop/Goodfellow et al/Advances in Neural Information Processing Systems 27/Goodfellow et al. - 2014 - Generative Adversarial Nets.pdf:pdf},
mendeley-groups = {VAKKEN/DL/LAB 2},
pages = {2672--2680},
publisher = {Curran Associates, Inc.},
title = {{Generative Adversarial Nets}},
url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
year = {2014}
}
@inproceedings{Gregor,
abstract = {This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.},
archivePrefix = {arXiv},
arxivId = {1502.04623},
author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
booktitle = {32nd International Conference on Machine Learning, ICML 2015},
eprint = {1502.04623},
file = {:home/senne/Documents/Mendeley Desktop/Gregor et al/32nd International Conference on Machine Learning, ICML 2015/Gregor et al. - 2015 - DRAW A recurrent neural network for image generation.pdf:pdf},
isbn = {9781510810587},
mendeley-groups = {VAKKEN/DL/LAB 2},
pages = {1462--1471},
title = {{DRAW: A recurrent neural network for image generation}},
volume = {2},
year = {2015}
}
@article{Alom2019,
abstract = {In recent years, deep learning has garnered tremendous success in a variety of application domains. This new field of machine learning has been growing rapidly and has been applied to most traditional application domains, as well as some new areas that present more opportunities. Different methods have been proposed based on different categories of learning, including supervised, semi-supervised, and un-supervised learning. Experimental results show state-of-the-art performance using deep learning when compared to traditional machine learning approaches in the fields of image processing, computer vision, speech recognition, machine translation, art, medical imaging, medical information processing, robotics and control, bioinformatics, natural language processing, cybersecurity, and many others. This survey presents a brief survey on the advances that have occurred in the area of Deep Learning (DL), starting with the Deep Neural Network (DNN). The survey goes on to cover Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). Additionally, we have discussed recent developments, such as advanced variant DL techniques based on these DL approaches. This work considers most of the papers published after 2012 from when the history of deep learning began. Furthermore, DL approaches that have been explored and evaluated in different application domains are also included in this survey. We also included recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys that have been published on DL using neural networks and a survey on Reinforcement Learning (RL). However, those papers have not discussed individual advanced techniques for training large-scale deep learning models and the recently developed method of generative models.},
author = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Chris and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Hasan, Mahmudul and {Van Essen}, Brian C. and Awwal, Abdul A.S. and Asari, Vijayan K.},
doi = {10.3390/electronics8030292},
file = {:home/senne/Documents/Mendeley Desktop/Alom et al/Electronics (Switzerland)/Alom et al. - 2019 - A state-of-the-art survey on deep learning theory and architectures.pdf:pdf},
issn = {20799292},
journal = {Electronics (Switzerland)},
keywords = {Auto-encoder (AE),Convolutional neural network (CNN),Deep belief network (DBN),Deep learning,Deep reinforcement learning (DRL),Generative adversarial network (GAN),Recurrent neural network (RNN),Restricted Boltzmann machine (RBM),Transfer learning},
mendeley-groups = {VAKKEN/DL/LAB 2},
number = {3},
pages = {1--67},
title = {{A state-of-the-art survey on deep learning theory and architectures}},
volume = {8},
year = {2019}
}
@article{Hochreiter:1997:LSM:1246443.1246450,
address = {Cambridge, MA, USA},
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
doi = {10.1162/neco.1997.9.8.1735},
issn = {0899-7667},
journal = {Neural Comput.},
mendeley-groups = {VAKKEN/DL/LAB 2},
month = {nov},
number = {8},
pages = {1735--1780},
publisher = {MIT Press},
title = {{Long Short-Term Memory}},
url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
volume = {9},
year = {1997}
}
